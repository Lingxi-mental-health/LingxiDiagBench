# ===================================
# Patient Test UI 配置文件
# ===================================

# Proxy 设置
http_proxy=
https_proxy=

# 后端服务端口
BACKEND_PORT=5001

# 患者数据路径
PATIENT_DATA_PATH=./raw_data/LingxiDiag-16K_validation_data.json

# 最大患者数
MAX_PATIENTS=100

# ===================================
# OpenRouter API 全局配置
# ===================================
OPENROUTER_API_KEY=""
OPENROUTER_SITE_URL=""
OPENROUTER_SITE_NAME="Patient Agent Test"
OPENROUTER_MAX_PARALLEL=16

# ===================================
# Reasoning 开关（按需关闭/开启）
# ===================================
# true 启用 reasoning；false 关闭 reasoning
# 注意：某些 OpenRouter 模型强制要求 reasoning（如 thinking/r1/o1 模型），
# 即使设置为 false，系统也会自动启用，避免 API 报错。
# 强制 reasoning 模型包括：
# - moonshotai/kimi-k2-thinking
# - deepseek-r1 系列
# - openai/o1, o3, o4 系列
# - 其他包含 "thinking", "-r1", "reasoner" 关键字的模型
PATIENT_AGENT_REASONING=false
DOCTOR_AGENT_REASONING=false

# ===================================
# 模型配置 - 每个 Agent 单独控制
# ===================================
# 可以为每个 Agent 单独指定是否使用 OpenRouter
# 支持混合部署：部分使用 OpenRouter，部分使用本地模型

# ===================================
# EverPsychosis (患者模拟) 配置
# ===================================
# 是否使用 OpenRouter (true/false)
PATIENT_USE_OPENROUTER=true

# OpenRouter 模型（当 PATIENT_USE_OPENROUTER=true 时使用）
OPENROUTER_PATIENT_MODEL=qwen/qwen3-32b

# 本地模型配置（当 PATIENT_USE_OPENROUTER=false 时使用）
OFFLINE_PATIENT_MODEL=../models/qwen3-32b
OFFLINE_PATIENT_PORTS=9040

# ===================================
# EverPsychiatrist (医生问诊) 配置
# ===================================
# 是否使用 OpenRouter (true/false)
DOCTOR_USE_OPENROUTER=true

# OpenRouter 模型（当 DOCTOR_USE_OPENROUTER=true 时使用）
OPENROUTER_DOCTOR_MODEL=qwen/qwen3-32b

# 本地模型配置（当 DOCTOR_USE_OPENROUTER=false 时使用）
OFFLINE_DOCTOR_MODEL=../models/qwen3-32b
OFFLINE_DOCTOR_PORTS=9041

# ===================================
# LingxiDiagnosis (诊断生成) 配置
# ===================================
# 是否使用 OpenRouter (true/false)
VERIFIER_USE_OPENROUTER=true

# OpenRouter 模型（当 VERIFIER_USE_OPENROUTER=true 时使用）
OPENROUTER_VERIFIER_MODEL=qwen/qwen3-32b

# 本地模型配置（当 VERIFIER_USE_OPENROUTER=false 时使用）
OFFLINE_VERIFIER_MODEL=../models/qwen3-32b
OFFLINE_VERIFIER_PORTS=9002

# ===================================
# VLLM 外部部署配置（可选）
# ===================================
# 如果 VLLM 服务部署在远程机器，可以指定 IP 地址
# 留空则使用 localhost

VLLM_DOCTOR_IP=
VLLM_PATIENT_IP=
VLLM_VERIFIER_IP=

# 示例：使用远程部署的模型
# VLLM_PATIENT_IP=10.119.28.185
# OFFLINE_PATIENT_PORTS=9028,9029

# ===================================
# RAG (Doctor V3) 配置
# ===================================
# DeepInfra API 密钥（RAG 功能必需）
DEEPINFRA_API_KEY=

# 是否使用 DeepInfra 进行 embedding（默认：true）
USE_DEEPINFRA_EMBEDDING=true

# DeepInfra Embedding 模型（默认：Qwen/Qwen3-Embedding-8B）
DEEPINFRA_EMBEDDING_MODEL=Qwen/Qwen3-Embedding-8B

# 是否启用重排序（默认：false）
ENABLE_RERANKING=false

# 本地 embedding 模型路径（仅当 USE_DEEPINFRA_EMBEDDING=false 时使用）
# LOCAL_EMBEDDING_MODEL_PATH=../models/paraphrase-multilingual-MiniLM-L12-v2

# ===================================
# 配置示例
# ===================================

# 示例 1: 全部使用 OpenRouter (推荐)
# PATIENT_USE_OPENROUTER=true
# DOCTOR_USE_OPENROUTER=true
# VERIFIER_USE_OPENROUTER=true
# OPENROUTER_API_KEY=sk-or-v1-your-api-key

# 示例 2: 全部使用本地模型
# PATIENT_USE_OPENROUTER=false
# DOCTOR_USE_OPENROUTER=false
# VERIFIER_USE_OPENROUTER=false
# OFFLINE_PATIENT_PORTS=9040
# OFFLINE_DOCTOR_PORTS=9041
# OFFLINE_VERIFIER_PORTS=9002

# 示例 3: 混合部署（Patient 和 Doctor 用 OpenRouter，Verifier 用本地）
# PATIENT_USE_OPENROUTER=true
# DOCTOR_USE_OPENROUTER=true
# VERIFIER_USE_OPENROUTER=false
# OPENROUTER_API_KEY=sk-or-v1-your-api-key
# OFFLINE_VERIFIER_PORTS=9002

# 示例 4: 使用远程 VLLM 服务
# PATIENT_USE_OPENROUTER=false
# VLLM_PATIENT_IP=10.119.28.185
# OFFLINE_PATIENT_PORTS=9028,9029
